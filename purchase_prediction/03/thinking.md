# 如何使用用户标签来指导业务（如何提升业务）

通过用户标签可以做精准推送。
在技术层面上，对算法建模及响应性能也有更高的要求：

推荐栏位、
消费周期评估、
广告投放、
促销排期


# 如果给你一堆用户数据，没有打标签。你该如何处理（如何打标签）

标签从何而来？典型的方式有：

* PGC：专家生产
* UGC：普通生产

标签是对高维事物的抽象（降维）

聚类算法：K-Means，EM聚类，Mean-Shift，DBSCAN，层次聚类，PCA

# 准确率和精确率有何不同（评估指标）

* 准确度=正确预测的概率

* 精准度=正确对某事预测的概率/所有预测为某事的概率

# 如果你使用大众点评，想要给某个餐厅打标签。这时系统可以自动提示一些标签，你会如何设计（标签推荐）
如何给用户推荐标签？当用户u给物品i打标签时，可以给用户推荐和物品i相关的标签，方法如下：
* 方法1：给用户u推荐整个系统最热门的标签
* 方法2：给用户u推荐物品i上最热门的标签
* 方法3：给用户u推荐他自己经常使用的标签
* 将方法2和3进行加权融合，生成最终的标签推荐结果


# 我们今天使用了10种方式来解MNIST，这些方法有何不同？你还有其他方法来解决MNIST识别问题么（分类方法）

* Logistic Regression
线性回归，模型简单，速度快，准确率不高

* CART，ID3（决策树）
决策树，模型的过程非常容易理解，
决策树模型可以可视化，非常直观

* LDA
计算速度快，充分利用了先验知识，缺点是当数据不是高斯分布时候，效果不好，降维之后的维数最多为类别数-1。

* 朴素贝叶斯
朴素贝叶斯算法假设了数据集属性之间是相互独立的，因此算法的逻辑性十分简单，并且算法较为稳定，当数据呈现不同的特点时，朴素贝叶斯的分类性能不会有太大的差异

* SVM

SVM的优化问题同时考虑了经验风险和结构风险最小化，因此具有稳定性。从几何观点，SVM的稳定性体现在其构建超平面决策边界时要求边距最大，因此间隔边界之间有充裕的空间包容测试样

* KNN

KNN方法思路简单，易于理解，易于实现，无需估计参数

* Adaboost

1. Adaboost作为分类器时，分类精度很高
2. 在Adaboost的框架下，可以使用各种回归分类模型来构建弱学习器，非常灵活。
3. 作为简单的二元分类器时，构造简单，结果可理解。
4. 不容易发生过拟合

* XGBoost
XGBoost使用了一阶和二阶偏导, 二阶导数有利于梯度下降的更快更准. 使用泰勒展开取得函数做自变量的二阶导数形式, 可以在不选定损失函数具体形式的情况下, 仅仅依靠输入数据的值就可以进行叶子分裂优化计算, 本质上也就把损失函数的选取和模型算法优化/参数选择分开了. 这种去耦合增加了XGBoost的适用性, 使得它按需选取损失函数, 可以用于分类, 也可以用于回归。

* TPOT

TPOT除了明显的节省时间的特点外，还有其他优点。这个应用的其中一个优点曾发表在 Airbnb的博客中，就是能够轻松创建基准。 这使我们能够判断现有ML模型的性能，并将他与其他模型的相关值进行关联。

* keras

keras只是一个工具包，封装了很多算法，使用起来比较灵活

* 其他方法

任何可用于分类的机器学习&深度学习算法都可以，如：RandomForest等

